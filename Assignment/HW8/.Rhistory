rm(list=ls())
library(cluster)
library(fpc)
data_file <- file.choose()
breast_cancer <- read.csv(data_file, na.string = "?")
View(breast_cancer)
rm(list=ls())
library(cluster)
library(fpc)
data_file <- file.choose()
admission_file <- read.csv(data_file, na.string = "?")
View(admission_file)
admission_file<-admission_file[-1]
admission_file<-na.omit(admission_file)#Remove any row with a missing value in any of the columns.
admission_file_pred<-admission_file[1]
View(admission_file)
hclust<-dist(admission_file)
hclust_results<-hclust(hclust)
plot(hclust_results)
hclust_2<-cutree(hclust_results,2)
View(hclust_2)
table(hclust_2,t(admission_file_pred))
plotcluster(admission_file,hclust_2)
admission_two_cols<- admission_file[c(2,3)]
View(admission_two_cols)
hclust<-dist(admission_two_cols)
hclust_results<-hclust(hclust)
plot(hclust_results)
hclust_2<-cutree(hclust_results,2)
View(hclust_2)
table(hclust_2,t(admission_file_pred))
plotcluster(admission_two_cols,hclust_2)
admission_file1<-read.csv(data_file,na.strings = ' ?')
admission_file1<-admission_file1[,-1]
admission_file1<-admission_file1[c(2,3)]
admission_file1<-read.csv(data_file,na.strings = ' ?')
admission_file1<-admission_file1[,-1]
admission_file1<-admission_file1[c(2,3)]
kmeans_2<- kmeans(admission_file1,2,nstart = 10)
kmeans_pred <- kmeans_2$cluster
table(kmeans_pred,admission_file1[,1])
plotcluster(admission_file1[-1],kmeans_pred)
rm(list=ls())
library(cluster)
library(fpc)
admission_file1<-read.csv(data_file,na.strings = ' ?')
admission_file1<-admission_file1[,-1]
admission_file1<-admission_file1[c(2,3)]
kmeans_2<- kmeans(admission_file1,2,nstart = 10)
kmeans_pred <- kmeans_2$cluster
table(kmeans_pred,admission_file1[,1])
plotcluster(admission_file1[-1],kmeans_pred)
data_file <- file.choose()
admission_file <- read.csv(data_file, na.string = "?")
View(admission_file)
admission_file1<-read.csv(data_file,na.strings = ' ?')
admission_file1<-admission_file1[,-1]
admission_file1<-admission_file1[c(2,3)]
kmeans_2<- kmeans(admission_file1,2,nstart = 10)
kmeans_pred <- kmeans_2$cluster
table(kmeans_pred,admission_file1[,1])
plotcluster(admission_file1[-1],kmeans_pred)
admission_file1<-read.csv(data_file,na.strings = ' ?')
admission_file1<-admission_file1[,-1]
admission_file1<-admission_file1[c(2,3)]
kmeans_2<- kmeans(admission_file1,2,nstart = 10)
kmeans_pred <- kmeans_2$cluster
table(kmeans_pred,admission_file1[,1])
plotcluster(admission_file1,kmeans_pred)
rm(list=ls())
#install.packages("randomForest")
library(randomForest)
data_file <- file.choose()
admission_cat<- read.csv(data_file,header = TRUE, na.strings=' ?')
View(admission_cat)
data_file <- file.choose()
admission_cat<- read.csv(data_file,header = TRUE, na.strings=' ?')
View(admission_cat)
#Data Preparation
admission_cat <- admission_cat[,-1]
cols <- ncol(admission_cat)
cols
admission_cat[1:cols] <- lapply(admission_cat[1:cols], factor)
View(admission_cat)
split<-sort(sample(nrow(admission_cat),round(.30*nrow(admission_cat))))
Training_Data <- admission_cat[-split,]
Testing_Data <- admission_cat[split,]
split<-sort(sample(nrow(admission_cat),round(.30*nrow(admission_cat))))
train_data <- admission_cat[-split,]
test_data <- admission_cat[split,]
rm(list=ls())
#install.packages("randomForest")
library(randomForest)
data_file <- file.choose()
admission_cat<- read.csv(data_file,header = TRUE, na.strings=' ?')
View(admission_cat)
#Data Preparation
admission_cat <- admission_cat[,-1]
#View(admission_cat)
cols <- ncol(admission_cat)
cols
admission_cat[1:cols] <- lapply(admission_cat[1:cols], factor)
View(admission_cat)
split<-sort(sample(nrow(admission_cat),round(.30*nrow(admission_cat))))
train_data <- admission_cat[-split,]
test_data <- admission_cat[split,]
fit <- randomForest( ADMIT~., data=train_data, importance=TRUE, ntree=1000)
importance(fit)
varImpPlot(fit)
Prediction <- predict(fit, test_data)
table(actual=test_data$ADMIT,Prediction)
tab<-table(actual=test_data$ADMIT,Prediction)
#Accuracy
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
rm(list=ls())
#install.packages("C50")
library(rpart)
library(rpart.plot)  			# Enhanced tree plots
library(rattle)           # Fancy tree plot
library(RColorBrewer)     # colors needed for rattle
library(class)
library(C50)
data_file <- file.choose()
admission_cat<- read.csv(data_file,header = TRUE, na.strings='?')
data_Factor <- colnames(admission_cat)
admission_cat[data_Factor] <- lapply(admission_cat[data_Factor], factor)
split<-sort(sample(nrow(admission_cat),round(.30*nrow(admission_cat))))
train_data <- admission_cat[-split,]
test_data <- admission_cat[split,]
rm(list=ls())
#install.packages("C50")
library(rpart)
library(rpart.plot)  			# Enhanced tree plots
library(rattle)           # Fancy tree plot
library(RColorBrewer)     # colors needed for rattle
library(class)
library(C50)
#Data Preparation
data_file <- file.choose()
admission_cat<- read.csv(data_file,header = TRUE, na.strings='?')
data_factor <- colnames(admission_cat)
admission_cat[data_factor] <- lapply(admission_cat[data_factor], factor)
#Splitting Data
split<-sort(sample(nrow(admission_cat),round(.30*nrow(admission_cat))))
train_data <- admission_cat[-split,]
test_data <- admission_cat[split,]
train_data$ADMIT <- as.factor(train_data$ADMIT)
model<-C5.0(ADMIT~., data = train_data, method = "class")
prediction_data<-predict(model,test_data,type="class")
plot(model)
table(test_data$ADMIT,prediction_data)
tab <- table(test_data$ADMIT,prediction_data)
#Accuracy
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
#  Course          : Knowledge Discovery And Data Mining
#  First Name      : Aakash
#  Last Name       : Rami
#  CWId            : 10453138
#  purpose         : Final Exam
rm(list=ls())
#install.packages("randomForest")
library(randomForest)
data_file <- file.choose()
admission_cat<- read.csv(data_file,header = TRUE, na.strings=' ?')
View(admission_cat)
#Data Preparation
admission_cat <- admission_cat[,-1]
#View(admission_cat)
cols <- ncol(admission_cat)
cols
admission_cat[1:cols] <- lapply(admission_cat[1:cols], factor)
View(admission_cat)
#Splitting Data
split<-sort(sample(nrow(admission_cat),round(.30*nrow(admission_cat))))
train_data <- admission_cat[-split,]
test_data <- admission_cat[split,]
#Model
fit <- randomForest( ADMIT~., data=train_data, importance=TRUE, ntree=1000)
importance(fit)
varImpPlot(fit)
Prediction <- predict(fit, test_data)
table(actual=test_data$ADMIT,Prediction)
tab<-table(actual=test_data$ADMIT,Prediction)
#Accuracy
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
#  Course          : Knowledge Discovery And Data Mining
#  First Name      : Aakash
#  Last Name       : Rami
#  CWId            : 10453138
#  purpose         : Final Exam
rm(list=ls())
#install.packages("C50")
library(rpart)
library(rpart.plot)  			# Enhanced tree plots
library(rattle)           # Fancy tree plot
library(RColorBrewer)     # colors needed for rattle
library(class)
library(C50)
#Data Preparation
data_file <- file.choose()
admission_cat<- read.csv(data_file,header = TRUE, na.strings='?')
data_factor <- colnames(admission_cat)
admission_cat[data_factor] <- lapply(admission_cat[data_factor], factor)
#Splitting Data
split<-sort(sample(nrow(admission_cat),round(.30*nrow(admission_cat))))
train_data <- admission_cat[-split,]
test_data <- admission_cat[split,]
train_data$ADMIT <- as.factor(train_data$ADMIT)
model<-C5.0(ADMIT~., data = train_data, method = "class")
prediction_data<-predict(model,test_data,type="class")
plot(model)
table(test_data$ADMIT,prediction_data)
tab <- table(test_data$ADMIT,prediction_data)
#Accuracy
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
data_file <- file.choose()
admission_cat<- read.csv(data_file,header = TRUE, na.strings='?')
admission_cat <-admission_cat[,-1]
View(admission_cat)
rm(list=ls())
#install.packages("C50")
library(rpart)
library(rpart.plot)  			# Enhanced tree plots
library(rattle)           # Fancy tree plot
library(RColorBrewer)     # colors needed for rattle
library(class)
library(C50)
#Data Preparation
data_file <- file.choose()
admission_cat<- read.csv(data_file,header = TRUE, na.strings='?')
admission_cat <-admission_cat[,-1]
data_factor <- colnames(admission_cat)
admission_cat[data_factor] <- lapply(admission_cat[data_factor], factor)
#Splitting Data
split<-sort(sample(nrow(admission_cat),round(.30*nrow(admission_cat))))
train_data <- admission_cat[-split,]
test_data <- admission_cat[split,]
#Convert variable admit into factor
train_data$ADMIT <- as.factor(train_data$ADMIT)
# C5.0 Model
model<-C5.0(ADMIT~., data = train_data, method = "class")
prediction_data<-predict(model,test_data,type="class")
plot(model)
table(test_data$ADMIT,prediction_data)
tab <- table(test_data$ADMIT,prediction_data)
#Accuracy
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
rm(list=ls())
#install.packages("randomForest")
library(randomForest)
data_file <- file.choose()
admission_cat<- read.csv(data_file,header = TRUE, na.strings=' ?')
View(admission_cat)
#Data Preparation
admission_cat <- admission_cat[,-1]
#View(admission_cat)
cols <- ncol(admission_cat)
cols
admission_cat[1:cols] <- lapply(admission_cat[1:cols], factor)
View(admission_cat)
#Splitting Data
split<-sort(sample(nrow(admission_cat),round(.30*nrow(admission_cat))))
train_data <- admission_cat[-split,]
test_data <- admission_cat[split,]
#Random Forest Model
fit <- randomForest( ADMIT~., data=train_data, importance=TRUE, ntree=1000)
importance(fit)
varImpPlot(fit)
Prediction <- predict(fit, test_data)
table(actual=test_data$ADMIT,Prediction)
tab<-table(actual=test_data$ADMIT,Prediction)
#Accuracy
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
## Fisrt Name:              Homa
##Last Name:               Deilamy
## Id:                    10445030
## Purpose:         Final Examination
## Quesion :              Problem 2
###An analyst has categorized the gre and the gpa variables into
#four categories: low, medium, high, and very high. Use the resulting
#dataset "Admission_cat" on CANVAS to develop the following two classification models
###1-Use the Random Forest methodology to develop a classification model for the Admission_cat
#dataset using gre, gpa and the rank variables as predictors. Use 30% of the records to create
#the test dataset and score the test dataset. What is the accuracy of your model?
## Clean up
rm(list = ls())
#Rad file
file<- file.choose()
Ad<- read.csv(file, colClasses = c("Application"="factor",
"ADMIT"="factor", "RANK"="factor",
"GPA"="factor", "GRE"="factor"))
View(Ad)
is.na(Ad)
## Creat tarining and test
index<- sort(sample(nrow(Ad), round(.30*nrow(Ad))))
training<-Ad[-index,]
test<-Ad[index,]
# Read library
#install.packages('randomForest')
library(randomForest)
fit<-randomForest(factor(GRE)~., data = training[,-1], importance=TRUE, ntree=300)
importance(fit)
varImpPlot(fit)
prediction<- predict(fit, test[,-1])
df<-as.data.frame(cbind(test,prediction))
table(actual=test$GRE,Prediction)
wrong<- (test$GRE!=Prediction )
error_rate<-sum(wrong)/length(wrong)
error_rate
rm(list=ls())
library(cluster)
library(fpc)
#Choose CSV
data_file <- file.choose()
admission_file <- read.csv(data_file, na.string = "?")
View(admission_file)
#Data Preperation
admission_file<-admission_file[-1]
#Remove any row with a missing value in any of the columns
admission_file<-na.omit(admission_file)
admission_file_pred<-admission_file[1]
View(admission_file)
#Hierarchical Clustering
admission_two_cols<- admission_file[c(2,3)]
View(admission_two_cols)
hclust<-dist(admission_two_cols)
hclust_results<-hclust(hclust)
plot(hclust_results)
hclust_2<-cutree(hclust_results,2)
View(hclust_2)
table(hclust_2,t(admission_file_pred))
plotcluster(admission_two_cols,hclust_2)
#Kmeans Clustering
admission_file1<-read.csv(data_file,na.strings = ' ?')
admission_file1<-admission_file1[,-1]
admission_file1<-admission_file1[c(2,3)]
kmeans_2<- kmeans(admission_file1,2,nstart = 10)
kmeans_pred <- kmeans_2$cluster
table(kmeans_pred,admission_file1[,1])
plotcluster(admission_file1,kmeans_pred)
#  Course          : Knowledge Discovery And Data Mining
#  First Name      : Aakash
#  Last Name       : Rami
#  CWId            : 10453138
#  purpose         : Final Exam
rm(list=ls())
#install.packages("randomForest")
library(randomForest)
# Choose CSV
data_file <- file.choose()
admission_cat<- read.csv(data_file,header = TRUE, na.strings=' ?')
View(admission_cat)
#Data Preparation
admission_cat <- admission_cat[,-1]
#View(admission_cat)
cols <- ncol(admission_cat)
cols
admission_cat[1:cols] <- lapply(admission_cat[1:cols], factor)
View(admission_cat)
#Splitting Data
split<-sort(sample(nrow(admission_cat),round(.30*nrow(admission_cat))))
train_data <- admission_cat[-split,]
test_data <- admission_cat[split,]
#Random Forest Model
fit <- randomForest( ADMIT~., data=train_data, importance=TRUE, ntree=1000)
importance(fit)
varImpPlot(fit)
Prediction <- predict(fit, test_data)
table(actual=test_data$ADMIT,Prediction)
tab<-table(actual=test_data$ADMIT,Prediction)
#Accuracy
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
#  Course          : Knowledge Discovery And Data Mining
#  First Name      : Aakash
#  Last Name       : Rami
#  CWId            : 10453138
#  purpose         : Final Exam
rm(list=ls())
#install.packages("C50")
library(rpart)
library(rpart.plot)  			# Enhanced tree plots
library(rattle)           # Fancy tree plot
library(RColorBrewer)     # colors needed for rattle
library(class)
library(C50)
#Data Preparation
data_file <- file.choose()
admission_cat<- read.csv(data_file,header = TRUE, na.strings='?')
admission_cat <-admission_cat[,-1]
data_factor <- colnames(admission_cat)
admission_cat[data_factor] <- lapply(admission_cat[data_factor], factor)
#Splitting Data
split<-sort(sample(nrow(admission_cat),round(.30*nrow(admission_cat))))
train_data <- admission_cat[-split,]
test_data <- admission_cat[split,]
#Convert variable admit into factor
train_data$ADMIT <- as.factor(train_data$ADMIT)
# C5.0 Model
model<-C5.0(ADMIT~., data = train_data, method = "class")
prediction_data<-predict(model,test_data,type="class")
plot(model)
table(test_data$ADMIT,prediction_data)
tab <- table(test_data$ADMIT,prediction_data)
#Accuracy
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
#  Course          : Knowledge Discovery And Data Mining
#  First Name      : Aakash
#  Last Name       : Rami
#  CWId            : 10453138
#  purpose         : Final Exam
rm(list=ls())
#install.packages("C50")
library(rpart)
library(rpart.plot)  			# Enhanced tree plots
library(rattle)           # Fancy tree plot
library(RColorBrewer)     # colors needed for rattle
library(class)
library(C50)
#Data Preparation
data_file <- file.choose()
admission_cat<- read.csv(data_file,header = TRUE, na.strings='?')
admission_cat <-admission_cat[,-1]
data_factor <- colnames(admission_cat)
admission_cat[data_factor] <- lapply(admission_cat[data_factor], factor)
#Splitting Data
split<-sort(sample(nrow(admission_cat),round(.30*nrow(admission_cat))))
train_data <- admission_cat[-split,]
test_data <- admission_cat[split,]
#Convert variable admit into factor
train_data$ADMIT <- as.factor(train_data$ADMIT)
# C5.0 Model
model<-C5.0(ADMIT~., data = train_data, method = "class")
prediction_data<-predict(model,test_data,type="class")
plot(model)
table(test_data$ADMIT,prediction_data)
tab <- table(test_data$ADMIT,prediction_data)
#Accuracy
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
